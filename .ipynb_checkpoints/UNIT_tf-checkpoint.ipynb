{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Image-image Translation(UNIT) TensorFlow Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funciton to chose the activation function\n",
    "def activate(linear, activation='leaky_relu'):\n",
    "        if activation == 'sigmoid':\n",
    "            return tf.nn.sigmoid(linear)\n",
    "        elif activation == 'softmax':\n",
    "            return tf.nn.softmax(linear)\n",
    "        elif activation == 'tanh':\n",
    "            return tf.nn.tanh(linear)\n",
    "        elif activation == 'relu':\n",
    "            return tf.nn.relu(linear)\n",
    "        elif activation == 'leaky_relu':\n",
    "            return tf.nn.leaky_relu(linear)\n",
    "        elif activation == 'linear':\n",
    "            return linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_conv_layer(input,           # The previous layer.\n",
    "                   num_input_channels, # Num. channels in prev. layer.\n",
    "                   filter_size,        # Width and height of each filter.\n",
    "                   num_filters,        # Number of filters.\n",
    "                   use_pooling=False,\n",
    "                   padding = 'SAME'\n",
    "                   strides=[1,1,1,1]\n",
    "                   activation='leaky_relu'): # Use 2x2 max-pooling.\n",
    "\n",
    "    # Shape of the filter-weights for the convolution.\n",
    "    # This format is determined by the TensorFlow API.\n",
    "    shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "\n",
    "    # Create new weights aka. filters with the given shape.\n",
    "    weights = tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "\n",
    "    # Create new biases, one for each filter.\n",
    "    biases = tf.Variable(tf.constant(1, shape=[length]))\n",
    "\n",
    "    # Create the TensorFlow operation for convolution.\n",
    "    # Note the strides are set to 1 in all dimensions.\n",
    "    # The first and last stride must always be 1,\n",
    "    # because the first is for the image-number and\n",
    "    # the last is for the input-channel.\n",
    "    # But e.g. strides=[1, 2, 2, 1] would mean that the filter\n",
    "    # is moved 2 pixels across the x- and y-axis of the image.\n",
    "    # The padding is set to 'SAME' which means the input image\n",
    "    # is padded with zeroes so the size of the output is the same.\n",
    "    layer = tf.nn.conv2d(input=input,\n",
    "                         filter=weights,\n",
    "                         strides=strides,\n",
    "                         padding=padding)\n",
    "\n",
    "    # Add the biases to the results of the convolution.\n",
    "    # A bias-value is added to each filter-channel.\n",
    "    layer += biases\n",
    "\n",
    "    # Use pooling to down-sample the image resolution?\n",
    "    if use_pooling:\n",
    "        # This is 2x2 max-pooling, which means that we\n",
    "        # consider 2x2 windows and select the largest value\n",
    "        # in each window. Then we move 2 pixels to the next window.\n",
    "        layer = tf.nn.max_pool(value=layer,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME')\n",
    "\n",
    "    # Activation of the layers (ReLU).\n",
    "    layer = activate(layer, activation='leaky_relu')\n",
    "\n",
    "    return layer, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_normalization_layer(input_layer):\n",
    "    \n",
    "    dimension = input_layer.get_shape().as_list()[-1]\n",
    "    \n",
    "    mean, variance = tf.nn.moments(input_layer, axes=[0, 1, 2])\n",
    "    \n",
    "    beta = tf.get_variable('beta', dimension, tf.float32,\n",
    "                               initializer=tf.constant_initializer(0.0, tf.float32))\n",
    "    \n",
    "    gamma = tf.get_variable('gamma', dimension, tf.float32,\n",
    "                                initializer=tf.constant_initializer(1.0, tf.float32))\n",
    "    \n",
    "    bn_layer = tf.nn.batch_normalization(input_layer, mean, variance, beta, gamma, BN_EPSILON=1e-10)\n",
    "\n",
    "    return bn_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_res_block(x, num_input_channels=3, filter_size=3, num_filters=1):\n",
    "    \n",
    "    residual = x\n",
    "    \n",
    "    layer_conv1, _ = create_conv_layer(input=x,\n",
    "                                       num_input_channels=num_input_channels,\n",
    "                                       filter_size=filter_size,\n",
    "                                       num_filters=num_filters,\n",
    "                                       use_pooling=False,\n",
    "                                       activation='linear')\n",
    "    \n",
    "    layer_bn1 = batch_normalization_layer(layer_conv1)\n",
    "\n",
    "    layer_norm1 = activate(layer_bn1, activation='relu')\n",
    "    \n",
    "    layer_conv2, _ = create_conv_layer(input=layer_norm1,\n",
    "                                       num_input_channels=num_input_channels,\n",
    "                                       filter_size=filter_size,\n",
    "                                       num_filters=num_filters,\n",
    "                                       use_pooling=False,\n",
    "                                       activation='linear')\n",
    "    \n",
    "    layer_bn2 = batch_normalization_layer(layer_conv2)\n",
    "    \n",
    "    layer_bn2 += residual\n",
    "    \n",
    "    layer_out = activate(layer_bn2, activation='relu')\n",
    "    \n",
    "    return layer_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_encoders(config, parameters):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generators(config, parameters):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_discrimiators(config, parameters):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
